{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a189a352d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to normalize the dataset\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))\n",
    "                                ])\n",
    "                                \n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 458)\n",
    "        self.fc2 = nn.Linear(458, 246)\n",
    "        self.fc3 = nn.Linear(246, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with a 0.2 drop probability \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.shape[0], -1)    \n",
    "        # Set the activation functions\n",
    "        layer1 = self.dropout(F.relu(self.fc1(x)))\n",
    "        layer2 = self.dropout(F.relu(self.fc2(layer1)))\n",
    "        layer3 = self.dropout(F.relu(self.fc3(layer2)))\n",
    "        layer4 = self.dropout(F.relu(self.fc4(layer3)))\n",
    "        \n",
    "        out = self.fc5(layer4)\n",
    "    \n",
    "        return out\n",
    "    \n",
    "model = Network()\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize =(6, 9), ncols =2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADECAYAAAA8lvKIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZIElEQVR4nO3de5SddX3v8fdn9kwyTO4k4RbAgRqliodKRwRSFQt4QQU9R3u46FpaVnO0akXUrthl1bbW5bGVenqqthyk1VNBq0BbxXjgaBHlpkkMFwErhCQkISYh5DpM5vbtH/tJ3c7ze5KdzMzz7Nn5vNaaxeS3f8/e370dv/PM7/L9KSIwM7NydFQdgJnZkcRJ18ysRE66ZmYlctI1MyuRk66ZWYmcdM3MSuSka1YxSR+X9I9Vx3GoJPVKCkmdh3l9SHpuwWNXSLot1VfS30r648OLunpOumYlkHS5pBWS9kh6StJySb9VUSwhaW8Wy0ZJ10iqVRFLkYj4SkS8quCxd0bEnwFIOk/ShnKjGx8nXbNJJulq4LPAJ4FjgZOBzwOXVBjWGRExEzgfuBz4vbEdDvcO1g7MSddsEkmaA/wp8O6IuDki9kbEUER8MyI+VHDN1yVtlrRT0p2SXtjw2EWSHpa0O7tL/WDWvkDStyTtkLRd0g8kHfT/3xHxKPAD4PSG4YIrJa0HviepQ9JHJK2TtEXSl7P31Oh3JW3K7uA/0BDrWZLuyWJ6StLfSJo25tqLJK2RtE3SX+yPWdLbJf2w4PP5B0mfkDQDWA6ckN2175F0gqR+SfMb+v+mpK2Sug72eZTBSddscp0DdAO3HMI1y4HFwDHAKuArDY99EfgfETELOB34Xtb+AWADsJD63fQfAQfd4y/pBcDLgJ80NL8C+HXg1cDbs69XAqcCM4G/GfM0r8zifRWwTNIFWfsI8H5gAfXP4Xzg98dc+yagDziT+p3/7x4s5v0iYi/wWmBTRMzMvjYBdwC/09D1rcBXI2Ko2eeeTE66ZpNrPrAtIoabvSAiro+I3RGxD/g4cEbD3eUQ8AJJsyPimYhY1dB+PPCc7E76B3HgwiqrJD0DfBO4Dvj7hsc+nt2RPwtcAVwTEWsiYg/wYeDSMUMPf5L1fzB7nsuy97EyIu6NiOGIWAv8HfWE3uh/RsT2iFhPfQjmsmY/pwP4EvVESzZWfRnwfyfgeSeEk67Z5HoaWNDs+KikmqRPSXpc0i5gbfbQguy//w24CFgn6fuSzsna/wJ4DLgt+3N92UFe6syImBcRvxYRH4mI0YbHnmz4/gRgXcO/1wGd1O+mU/3XZdcg6XnZkMfm7L18suF9HPDacfoX6r+YTgUuBHZGxI8m4HknhJOu2eS6BxgA3thk/8up/5l9ATAH6M3aBRARP46IS6gPPfwz8E9Z++6I+EBEnAq8Abha0vmHGXPjHfIm4DkN/z4ZGAZ+0dB20pjHN2XffwF4FFgcEbOpD3lozGsVXXs4sdYbIgaofy5XAG+jhe5ywUnXbFJFxE7go8DnJL1RUo+kLkmvlfTpxCWzgH3U75B7qN8dAiBpWrZ+dU42PrmL+rgpkl4v6bmS1NA+MgFv4Ubg/ZJOkTQzi+drY4ZL/jh7Xy8E3gF8reG97AL2SDoNeFfi+T8kaZ6kk4D3NVzbrF8A8xOTe1+mPhZ9MdBSa6CddM0mWURcA1wNfATYSv1P6vdQv1Md68vU/8zeCDwM3Dvm8bcBa7M/199JNnZJfSLr/wN7qN9dfz4i7piA8K+nfqd4J/AE9bv2947p833qQxvfBf4yIvZvavgg9Tv33cD/IZ1Q/wVYCawGbqU+Udi0bPXFjcCabJXECVn7XcAosCobT24ZchFzM2tHkr4H3BAR11UdSyMnXTNrO5JeAtwOnBQRu6uOp5GHF8ysrUj6EvWhlqtaLeGC73TNzEp1wLWDF3a8ZUplZHWN3WEIMVIwgTt6CBO7HYlaIIdyfYnUmf6fNIabXptfqttHvz52CZFZW/PwgplZiVxFyI5ICxYsiN7e3qrDsDa1cuXKbRGxMPWYk64dkXp7e1mxYkXVYVibkrSu6LEpmXRTY7cAMTQ4OS84zvHbHW87J9d22bLlyb7/3n9cru2uG85M9j3ur+7OtRWO3U6hcWmzduYxXTOzEjnpmpmVyEnXzKxETrpmZiVy0jUzK9GUXL1wKKsUzr0/3bdvxppc2127n5fs+43vLMnHkPh19a///TPJ64dy1flg8/CsZN/Tpj+Va7vqqu8m+159yZvzr3Ve/nogvVIhtaKhqK+ZTQjf6VpbkPQ+SQ9J+qmkq6qOx6yIk65NeZJOB34POAs4A3i9pMXVRmWW5qRr7eDXgXsjoj87Rub71I/2Nms5TrrWDh4CXi5pvqQe6qflnjS2k6SlklZIWrF169bSgzSDg9TTLbO0o6ZPT7bHvn25tv43vTTZ988/83e5tuNqe5N9nxyenei7J9m3W/mJpd2jXbm29cPzktdvGkq3p8yqDeTa9o6mP5s3zvx5rm3JD96d7Hvq5atzbR09Pcm+o/39B4hwYk1UaUdJVwLvpn5G2MPAsxHx/qL+fX194doLNlkkrYyIvtRjvtO1thARX4yIMyPi5cB2IP8byawFTMklY2ZjSTomIrZIOhn4r0C+ypBZC3DStXZxk6T5wBDw7oh4puqAzFKcdK0tRMTLqo7BrBke0zUzK1HL3OnGUPMHJ372mv+dbJ/bkd/ye9ezvcm+NeUXZjw+eGyy7zPDM3JtQ5HfQjszsfIAYFZHvr2m0WTfl3Svz7VtKtgy/PBgvv3WJZ9L9n0v+a3MhasUlFhQ4FOjzSZEyyRdszI9uHEnvctu/c9/r/3U6yqMxo4kHl4wMyuRk661BUnvz4rdPCTpRkndVcdkluKka1OepEXAHwB9EXE6UAMurTYqs7RqxnTHeTLtDdvPTrZfMm9Vrm12weTWYGIibJrS9WWP78ov+RyI/InE3UrX7p3fmd9eXCM9MdU/mv+f5KTOXcm+Dw7mTw4+NtJbmYfP/81cW+d3Vyb7diS2ZI8OpD/HFtIJHCVpCOgBNlUcj1mS73RtyouIjcBfAuuBp4CdEXFbtVGZpTnp2pQnaR5wCXAKcAIwQ9JbE/3+s8rYSP/OssM0A5x0rT1cADwREVsjYgi4GTh3bKeIuDYi+iKir9Yzp/QgzcBJ19rDeuBsST2SBJwPPFJxTGZJTro25UXEfcA3gFXAg9R/rq+tNCizApWsXlAtv0ogClYvdJ7am2t7y7ybkn03jzT/J+NAogh5V6JYeZEZyhdXX9SZLmy1MFFIfYR07e6BxKqKIl3Kb52e25HeXrzuyvx7+7X0IcOMJgrHt7qI+BjwsarjMDsYbwO2I9KLFs1hhbf+WgU8vGBmViInXTOzEnl4wY5IY6uMNcOVyGwiVJJ0Yyi9XTbl55/Mn9p7Yuezyb4bC07jTSnaHjweexNbgwEGhvOTdsfV0lt7UzWBByP9B0mqTu8vRvKvBfDNcz+fa7sqv5S1zrVzzSaNhxdsypP0fEmrG752Sbqq6rjMUjy8YFNeRPwM+A0ASTVgI3BLlTGZFfGdrrWb84HHI2Jd1YGYpTjpWru5FLix6iDMijjpWtuQNA24GPh6weOuMmaVa/kx3buXfCHXtmY4X2Qb0ttiByI9m9+d6DtSsEogZTTx+6qoMHm3hnJtO0aPSvad1ZFf1ZA6uRhgYUf+NN8nh9NboY+p5Yubd/aenOw7vDZ/IvEU8VpgVUT8IvVgRFxLVpNh+vGLvUTDKuE7XWsnl+GhBWtxTrrWFiT1ABdSr6Vr1rJafnjBrBkR0Q/MrzoOs4Nx0rUjkquMWVVaJul29PQk2x8empFr6x9NT6TVlK8lO1vp7b6perZDkf44uhNbc2vkX+vpkZnpuBJ9OxKxAvR05GvZvnhaehRow3B+O3Rqgg/gxM78xOH63zkx2feET0/ZiTSzlucxXTOzErXMna5ZmYqqjLmSmE023+mamZXISdfagqS5kr4h6VFJj0g6p+qYzFI8vGDt4n8B34mIN2fbgdMzs2YVa5mk23HswmR7agttP+nVC+M1P7FVFtLbi1NbfucmtuUCbB6em2vbPdqd7Lu4M/9+nxpJr3Q4pSu/WuLJkfRJvjtH8/G+4i0rk31//ulkc8uSNBt4OfB2gIgYBJqvlG9WIg8vWDs4FdgK/L2kn0i6TlJuraEL3lgrcNK1dtAJnAl8ISJeDOwFlo3tFBHXRkRfRPTVetKFgcwmm5OutYMNwIaIuC/79zeoJ2GzluOka1NeRGwGnpT0/KzpfODhCkMyK9QyE2n7etO1Sk6q5SeGNhfUjE1NuhVJ/bYp2po7I/G80zWSa9sXteT1x3XuyLV1FWwZnlfLT7q/+sPvSvZ9y4duy7W9dfb9yb5rhvPP+5kTfpjsezEvSba3uPcCX8lWLqwB3lFxPGZJLZN0zcYjIlYDfVXHYXYwTrp2RHKVMauKx3TNzErkpGtmViInXTOzErXMmO6aN05Ltvd05FcEFBXqnpZYUTBYsKIg1bdoa+4A+ROF59f25tq6E88JUIv8FtzZHeni6inzvnRPsv3Rdx2fazt63qPJvqsG86sXphcUeK/NPzrXNvL09gOFaGZNapmkazYektYCu4ERYDgivJLBWpKTrrWTV0bEtqqDMDsQj+mamZXISdfaRQC3SVopaWmqQ2OVsa1bt5YcnlldywwvvOf8/JZWgE3D+UmoQ9num5owg/RpwCOR/h20N/L1e1NbkZcctTYdROI04V3D6Uk7EicHF/m3f39erm36yemtvQOj+YnKJ4bSf4nvfsXiXFvPzfcleraUJRGxSdIxwO2SHo2IOxs7RMS1wLUAfX19+R8ssxL4TtfaQkRsyv67BbgFOKvaiMzSnHRtypM0Q9Ks/d8DrwIeqjYqs7SWGV4wG4djgVskQf1n+oaI+E61IZmlOenalBcRa4Azqo7DrBktk3SvPnpNsv3egfwkVtFEWqoe7jTSE2l7Iz+xVLTTLbV7LHWI5U8Hj0lef9q0/Ex58Y609A66lONuTeziu6Dpywtte1E+hpNvHv/zmpnHdM3MSuWka2ZWIiddOyI9uHEnvctupXfZrVWHYkcYJ10zsxI56VrbkFST9BNJ36o6FrMilaxe6DxxUaJ1ddPXH8o24NR236Ln6KqlVzoMJWryFm0ZThkoqOk7XnOXJ04Z/6t03+7EVuQiI0dN2R2y7wMeAWZXHYhZEd/pWluQdCLwOuC6qmMxOxAnXWsXnwX+kANUDGqsMjbSv7O0wMwaOenalCfp9cCWiFh5oH4RcW1E9EVEX60nXyXOrAxOutYOlgAXZ0f2fBX4bUn/WG1IZmmVTKSNLJzbfN/ERNiMgom0wdTvkIIJr8FD2G47t+PZpuIaiPwBlgDbR/KHQvZ07Ct4tebjGtm1q+m+czv6c20DBZ/N0Nz0hGKriogPAx8GkHQe8MGIeGuVMZkV8Z2umVmJWqbgjdlEiIg7gDsqDsOskJOuHZFetGgOKz71uqrDsCOQhxfMzErkO107Iu0veLPfWt/1WkkqSbrDc/OFyYvUGN+W1FRhc4BapLcHp6S2AacUFUwfTLxUd8EpxU8MFa1qaM4ntp2WbL9izopcW3/B++pZuHdcMZhZMQ8vmJmVyEnXpjxJ3ZJ+JOl+ST+V9CdVx2RWxGO61g72Ab8dEXskdQE/lLQ8Iu6tOjCzsZx0bcqLiAD2nxTalX1N2fqU1t4qSbpPv6C76b5dBRNOKdMSBaaSW4OBbg3n2gYi/XHsGM1v403W4008J8COxDbghYltuQDrhsdXCvaLK5ck26+6cHWu7f7BxGnCwPyZ6dhamaQasBJ4LvC5iLgv0WcpsBSgNnthuQGaZTyma20hIkYi4jeAE4GzJJ2e6OMqY1Y5J11rKxGxg/o24NdUG4lZmpOuTXmSFkqam31/FHAB8GilQZkV8ESatYPjgS9l47odwD9FhA+ntJbkpGtTXkQ8ALy46jjMmlFJ0h1N1/pOSq0oKCpi3qH8KqFapFcOHcrzzqjl23eMHpVrGypY/ZBa6TBUMLKTWilxKDq3pFckjCRWUBVtsT5hZv78sGfGFVXrcZUxq4rHdM3MSuSka2ZWIiddM7MSOenalCfpJEn/JumRrODN+6qOyaxIJRNpx/6o+XqtI4fwe2E0USO3q6Ce7u7R/FvfMpqu8zu/lo93YaJtqOB03V3RfP3gWYmThw/FgvvTk2NdVzR/yvBRiYnDFp9IGwY+EBGrJM0CVkq6PSIerjows7F8p2tTXkQ8FRGrsu93A48Ai6qNyizNSdfaiqRe6mt2cwVvzFqBk661DUkzgZuAqyJiV+LxpZJWSFqxdevW8gM0w0nX2kRWvPwm4CsRcXOqT2OVsYULXdrRquGka1OeJAFfBB6JiGuqjsfsQCpZvdAx2Hxh8tohFSbPP29qRQPArI6BXNveSG+h3TySLyye2to7Q4PJ60cTqxqKVjr0Td+TbG/W0Xc+mWx/aiQfW7fS+7GPmb4717ZpXFFNuiXA24AHJa3O2v4oIr5dXUhmaS54Y1NeRPwQSP92NWsxHl4wMyuRk66ZWYmcdM3MSlTNRNqO/BbaBwbzE1t1+cmt1MQUwO7Ib3UtOk04dXJwanIMYFpH/jkGIj8JtWs0fcpxLbEVOVWPF+An+/LbeDt7T072HV67Pt+2YWOy7x39z821vazn8WTfvcOpbcv7kn2nqgc37qR32a2Fj691rV2bJL7TNTMrkZOutQVJ10vaIumhqmMxOxAnXWsX/4CPXbcpwEnX2kJE3AlsrzoOs4Nx0jUzK1ElqxdGHnsi17Z5eFay70u7c8Wi2Dna/DbivaPp3yujqQ1M6frfDCa6djGca+soKJiefP2CFRhdyj9v7B1fYXOAxweOybW9esZjyb7bB1MnEk/91QuSlgJLAWqzXfDGquE7XTtiNFYZq/XMqTocO0I56ZqZlchJ19qCpBuBe4DnS9og6cqqYzJLcZUxawsRcVnVMZg1o2WS7te2vTTZ/nXlZ7eKJqz+etGdubbl++Yl+87t6M+19XSkJ4tmJCa35tTyfYvO201N+x1fS01WwTXPLM5fPwFHy+wYzr9eUQxP7Do61za71c8DPkQvWjSHFd7qaxXw8IKZWYmcdM3MSuSka2ZWIiddM7MSOelaW5D0Gkk/k/SYpGVVx2NWpGVWL2w4e3yn4AJczEvGdX1Hd7oIuY5KFBxfkF8VMbwgvZV5eEb+Y+4/Ln0S75zH8qsq4IFk30Oxayj/3mpK/87duTf/fvPnIbcOSTXgc8CFwAbgx5L+NSIerjYyszzf6Vo7OAt4LCLWRMQg8FXgkopjMkty0rV2sAh4suHfG7K2XyFpqaQVklZsnYC1z2aHw0nX2kGiDly+ZlxjwZuFC11lzKrhpGvtYANwUsO/TwQ2VRSL2QFVM5Gm/I2JOtMTS0R+y28M57flToTRgYITiVPtz+S3xern6ctT76zswoJdiRONP7HttGTfocfTE4It7MfAYkmnABuBS4HLqw3JLK1lVi+YHa6IGJb0HuD/US+BcX1E/LTisMySnHStLUTEt4FvVx2H2cF4TNfMrEROumZmJXLSNTMrUTVjupEvTB5Dg+N/3o58GXF1pJZwAgVbYNPPm1htkViBcUg60q8fQ4nTgCfgs9l09u58G+ltz6dyz7hfz8zSfKdrZlYiJ10zsxI56ZqZlcjrdO2ItHLlyj2SflZ1HMACYFvVQWQcS97hxvGcogcUiUkts3YnaUVE9DmOX3Is5cTh4QUzsxI56ZqZlchJ145U11YdQKZV4gDHkjLhcXhM18ysRL7TNTMrkZOutZWDHcWuur/OHn9A0pnNXjsJsVyRxfCApLslndHw2FpJD0paLWnFJMdxnqSd2WutlvTRZq+dhFg+1BDHQ5JGJB2dPTaRn8n1krZIeqjg8cn7OYkIf/mrLb6oFzB/HDgVmAbcD7xgTJ+LgOXUz1U7G7iv2WsnIZZzgXnZ96/dH0v277XAgpI+k/OAbx3OtRMdy5j+bwC+N9GfSfZcLwfOBB4qeHzSfk58p2vtpJmj2C8Bvhx19wJzJR3f5LUTGktE3B0R+899upf62W4TbTzvq/TPZIzLgBvH8XqFIuJOYPsBukzaz4mTrrWTZo5iL+rT1DHuExxLoyup31ntF8BtklZKWlpCHOdIul/SckkvPMRrJzoWJPUArwFuamieqM+kGZP2c+JtwNZOmjmKvahPU8e4T3As9Y7SK6kn3d9qaF4SEZskHQPcLunR7O5sMuJYBTwnIvZIugj4Z2Bxk9dOdCz7vQG4KyIa70Yn6jNpxqT9nPhO19pJM0exF/WZ6GPcm3o+Sf8FuA64JCKe3t8eEZuy/24BbqH+Z+2kxBERuyJiT/b9t4EuSQuafQ8TGUuDSxkztDCBn0kzJu/nZCIGpf3lr1b4ov6X2xrgFH45yfHCMX1ex69OkPyo2WsnIZaTgceAc8e0zwBmNXx/N/CaSYzjOH65Zv8sYH32+ZT+mWT95lAfb50xGZ9Jw3P2UjyRNmk/Jx5esLYRBUexS3pn9vjfUj8x+CLqya4feMeBrp3kWD4KzAc+n51EMhz14irHArdkbZ3ADRHxnUmM483AuyQNA88Cl0Y9w1TxmQC8CbgtIvY2XD5hnwmApBupr9pYIGkD8DGgqyGOSfs58Y40M7MSeUzXzKxETrpmZiVy0jUzK5GTrplZiZx0zcxK5KRrZlYiJ10zsxI56ZqZleg/AOEIwaUnmpdCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])                          # ps is probablity\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train loss: 0.613\n",
      "Test loss: 0.837\n",
      "Test accuracy: 83.74%\n",
      "====================================================================================================\n",
      "Epoch 2/100\n",
      "Train loss: 0.444\n",
      "Test loss: 0.846\n",
      "Test accuracy: 84.56%\n",
      "====================================================================================================\n",
      "Epoch 3/100\n",
      "Train loss: 0.403\n",
      "Test loss: 0.857\n",
      "Test accuracy: 85.72%\n",
      "====================================================================================================\n",
      "Epoch 4/100\n",
      "Train loss: 0.378\n",
      "Test loss: 0.856\n",
      "Test accuracy: 85.61%\n",
      "====================================================================================================\n",
      "Epoch 5/100\n",
      "Train loss: 0.359\n",
      "Test loss: 0.873\n",
      "Test accuracy: 87.28%\n",
      "====================================================================================================\n",
      "Epoch 6/100\n",
      "Train loss: 0.346\n",
      "Test loss: 0.865\n",
      "Test accuracy: 86.51%\n",
      "====================================================================================================\n",
      "Epoch 7/100\n",
      "Train loss: 0.333\n",
      "Test loss: 0.874\n",
      "Test accuracy: 87.44%\n",
      "====================================================================================================\n",
      "Epoch 8/100\n",
      "Train loss: 0.323\n",
      "Test loss: 0.874\n",
      "Test accuracy: 87.37%\n",
      "====================================================================================================\n",
      "Epoch 9/100\n",
      "Train loss: 0.314\n",
      "Test loss: 0.877\n",
      "Test accuracy: 87.70%\n",
      "====================================================================================================\n",
      "Epoch 10/100\n",
      "Train loss: 0.305\n",
      "Test loss: 0.881\n",
      "Test accuracy: 88.14%\n",
      "====================================================================================================\n",
      "Epoch 11/100\n",
      "Train loss: 0.297\n",
      "Test loss: 0.880\n",
      "Test accuracy: 87.96%\n",
      "====================================================================================================\n",
      "Epoch 12/100\n",
      "Train loss: 0.293\n",
      "Test loss: 0.879\n",
      "Test accuracy: 87.95%\n",
      "====================================================================================================\n",
      "Epoch 13/100\n",
      "Train loss: 0.289\n",
      "Test loss: 0.868\n",
      "Test accuracy: 86.75%\n",
      "====================================================================================================\n",
      "Epoch 14/100\n",
      "Train loss: 0.277\n",
      "Test loss: 0.886\n",
      "Test accuracy: 88.55%\n",
      "====================================================================================================\n",
      "Epoch 15/100\n",
      "Train loss: 0.275\n",
      "Test loss: 0.888\n",
      "Test accuracy: 88.75%\n",
      "====================================================================================================\n",
      "Epoch 16/100\n",
      "Train loss: 0.269\n",
      "Test loss: 0.884\n",
      "Test accuracy: 88.42%\n",
      "====================================================================================================\n",
      "Epoch 17/100\n",
      "Train loss: 0.268\n",
      "Test loss: 0.880\n",
      "Test accuracy: 87.96%\n",
      "====================================================================================================\n",
      "Epoch 18/100\n",
      "Train loss: 0.263\n",
      "Test loss: 0.886\n",
      "Test accuracy: 88.58%\n",
      "====================================================================================================\n",
      "Epoch 19/100\n",
      "Train loss: 0.259\n",
      "Test loss: 0.884\n",
      "Test accuracy: 88.42%\n",
      "====================================================================================================\n",
      "Epoch 20/100\n",
      "Train loss: 0.256\n",
      "Test loss: 0.888\n",
      "Test accuracy: 88.84%\n",
      "====================================================================================================\n",
      "Epoch 21/100\n",
      "Train loss: 0.252\n",
      "Test loss: 0.889\n",
      "Test accuracy: 88.92%\n",
      "====================================================================================================\n",
      "Epoch 22/100\n",
      "Train loss: 0.247\n",
      "Test loss: 0.887\n",
      "Test accuracy: 88.68%\n",
      "====================================================================================================\n",
      "Epoch 23/100\n",
      "Train loss: 0.245\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.15%\n",
      "====================================================================================================\n",
      "Epoch 24/100\n",
      "Train loss: 0.242\n",
      "Test loss: 0.890\n",
      "Test accuracy: 88.95%\n",
      "====================================================================================================\n",
      "Epoch 25/100\n",
      "Train loss: 0.237\n",
      "Test loss: 0.891\n",
      "Test accuracy: 89.08%\n",
      "====================================================================================================\n",
      "Epoch 26/100\n",
      "Train loss: 0.232\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.18%\n",
      "====================================================================================================\n",
      "Epoch 27/100\n",
      "Train loss: 0.233\n",
      "Test loss: 0.891\n",
      "Test accuracy: 89.09%\n",
      "====================================================================================================\n",
      "Epoch 28/100\n",
      "Train loss: 0.230\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.17%\n",
      "====================================================================================================\n",
      "Epoch 29/100\n",
      "Train loss: 0.227\n",
      "Test loss: 0.888\n",
      "Test accuracy: 88.82%\n",
      "====================================================================================================\n",
      "Epoch 30/100\n",
      "Train loss: 0.225\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.22%\n",
      "====================================================================================================\n",
      "Epoch 31/100\n",
      "Train loss: 0.221\n",
      "Test loss: 0.896\n",
      "Test accuracy: 89.57%\n",
      "====================================================================================================\n",
      "Epoch 32/100\n",
      "Train loss: 0.216\n",
      "Test loss: 0.886\n",
      "Test accuracy: 88.59%\n",
      "====================================================================================================\n",
      "Epoch 33/100\n",
      "Train loss: 0.221\n",
      "Test loss: 0.894\n",
      "Test accuracy: 89.40%\n",
      "====================================================================================================\n",
      "Epoch 34/100\n",
      "Train loss: 0.211\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.24%\n",
      "====================================================================================================\n",
      "Epoch 35/100\n",
      "Train loss: 0.208\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.20%\n",
      "====================================================================================================\n",
      "Epoch 36/100\n",
      "Train loss: 0.210\n",
      "Test loss: 0.892\n",
      "Test accuracy: 89.20%\n",
      "====================================================================================================\n",
      "Epoch 37/100\n",
      "Train loss: 0.209\n",
      "Test loss: 0.889\n",
      "Test accuracy: 88.94%\n",
      "====================================================================================================\n",
      "Epoch 38/100\n",
      "Train loss: 0.209\n",
      "Test loss: 0.889\n",
      "Test accuracy: 88.88%\n",
      "====================================================================================================\n",
      "Epoch 39/100\n",
      "Train loss: 0.211\n",
      "Test loss: 0.894\n",
      "Test accuracy: 89.37%\n",
      "====================================================================================================\n",
      "Epoch 40/100\n",
      "Train loss: 0.204\n",
      "Test loss: 0.896\n",
      "Test accuracy: 89.59%\n",
      "====================================================================================================\n",
      "Epoch 41/100\n",
      "Train loss: 0.201\n",
      "Test loss: 0.895\n",
      "Test accuracy: 89.50%\n",
      "====================================================================================================\n",
      "Epoch 42/100\n",
      "Train loss: 0.201\n",
      "Test loss: 0.894\n",
      "Test accuracy: 89.42%\n",
      "====================================================================================================\n",
      "Epoch 43/100\n",
      "Train loss: 0.200\n",
      "Test loss: 0.893\n",
      "Test accuracy: 89.28%\n",
      "====================================================================================================\n",
      "Epoch 44/100\n",
      "Train loss: 0.197\n",
      "Test loss: 0.898\n",
      "Test accuracy: 89.79%\n",
      "====================================================================================================\n",
      "Epoch 45/100\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "benchmark_accuracy = 0.80\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    \n",
    "    running_accuracy = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    # training\n",
    "    for x_train_batch, y_train_batch in trainloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(x_train_batch)\n",
    "        train_preds = torch.argmax(logits.detach(), dim=1)\n",
    "\n",
    "        # loss\n",
    "        train_loss = criterion(logits, y_train_batch)\n",
    "        running_loss += train_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n",
    "        running_accuracy += train_acc.item()\n",
    "\n",
    "        # backward pass\n",
    "        train_loss.backward()\n",
    "\n",
    "        # update paramaters\n",
    "        optimizer.step()\n",
    "\n",
    "    # mean loss (all batches losses divided by the total number of batches)\n",
    "    train_losses.append(running_loss / len(trainloader))\n",
    "    \n",
    "    # mean accuracies\n",
    "    train_accuracies.append(running_accuracy / len(trainloader))\n",
    "    \n",
    "    # print\n",
    "    print(f'Train loss: {train_losses[-1] :.3f}')\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        running_accuracy = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for x_test_batch, y_test_batch in testloader:\n",
    "            \n",
    "            # logits\n",
    "            test_logits = model(x_test_batch)\n",
    "\n",
    "            # predictions\n",
    "            test_preds = torch.argmax(test_logits, dim=1)\n",
    "            \n",
    "            # accuracy\n",
    "            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n",
    "            running_accuracy += test_acc.item()\n",
    "\n",
    "            # loss\n",
    "            test_loss = criterion(test_logits, y_test_batch)\n",
    "            running_loss += test_loss.item()\n",
    "\n",
    "        # mean accuracy for each epoch\n",
    "        test_accuracies.append(running_accuracy / len(testloader))\n",
    "\n",
    "        # mean loss for each epoch\n",
    "        test_losses.append(running_accuracy / len(testloader))\n",
    "\n",
    "         # print\n",
    "        print(f'Test loss: {test_losses[-1] :.3f}')\n",
    "        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n",
    "        print('='*100)\n",
    "\n",
    "        # saving best model\n",
    "        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n",
    "        if test_accuracies[-1] > benchmark_accuracy:\n",
    "\n",
    "            # save model \n",
    "            torch.save(model.state_dict(), './model.pth')\n",
    "\n",
    "            # update benckmark\n",
    "            benchmark_accuracy = test_accuracies[-1]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# Plots\n",
    "x_epochs = list(range(epochs))\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_epochs, train_losses, marker='o', label='train')\n",
    "plt.plot(x_epochs, test_losses, marker='o', label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_epochs, train_accuracies, marker='o', label='train')\n",
    "plt.plot(x_epochs, test_accuracies, marker='o', label='test')\n",
    "plt.axhline(benchmark_accuracy, c='grey', ls='--',\n",
    "            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('./learning_curve.png', dpi = 200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint1.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8abb0779bf248a90442b2ba375cb2dc444ddbc86bf34dd34983763988490020e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
