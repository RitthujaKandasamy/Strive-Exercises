{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from datahandler import testloader\n",
    "from model import ConvNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model_state = torch.load('model.pth')\n",
    "model = ConvNet()\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize predictions\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze(), cmap = 'Greys_r')\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2992ee27280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('images\\\\6.png')\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "retval, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Type must be a sub-type of ndarray type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ritth\\code\\Strive\\Strive-Exercises\\Chapter 03\\07. Minst data CNN\\predict.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/07.%20Minst%20data%20CNN/predict.ipynb#ch0000004?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/07.%20Minst%20data%20CNN/predict.ipynb#ch0000004?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/07.%20Minst%20data%20CNN/predict.ipynb#ch0000004?line=3'>4</a>\u001b[0m     log_soft \u001b[39m=\u001b[39m model(img\u001b[39m.\u001b[39;49mview(\u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49mimg[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/07.%20Minst%20data%20CNN/predict.ipynb#ch0000004?line=4'>5</a>\u001b[0m ps \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(log_soft)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/07.%20Minst%20data%20CNN/predict.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39m#view_classify(img, ps)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Type must be a sub-type of ndarray type"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_soft = model(img.view(1, *img[0].shape))\n",
    "ps = torch.exp(log_soft)\n",
    "#view_classify(img, ps)\n",
    "print(np.argmax(ps))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a404c1b23560d548308d831c1aa8041fb180aef1b35cf4a28ead3655e6085d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
