{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a transformation to normalize the dataset\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))\n",
    "                                ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST(\"~/.pytorch/F_MNIST_data/\", download=True, train=False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Creating a function to visualize the dataset\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "  \"\"\"Imshow for Tensor.\"\"\"\n",
    "  if ax is None:\n",
    "      fig, ax = plt.subplots()\n",
    "  image = image.numpy().transpose((1, 2, 0))\n",
    "   \n",
    "  if normalize:\n",
    "      mean = np.array([0.485, 0.456, 0.406])\n",
    "      std = np.array([0.229, 0.224, 0.225])\n",
    "      image = std * image + mean\n",
    "      image = np.clip(image, 0, 1)\n",
    "\n",
    "  ax.imshow(image)\n",
    "  ax.spines['top'].set_visible(False)\n",
    "  ax.spines['right'].set_visible(False)\n",
    "  ax.spines['left'].set_visible(False)\n",
    "  ax.spines['bottom'].set_visible(False)\n",
    "  ax.tick_params(axis='both', length=0)\n",
    "  ax.set_xticklabels('')\n",
    "  ax.set_yticklabels('')\n",
    "\n",
    "  return ax\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "imshow(image[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x26c69f0a170>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 9, 0, 7, 9, 4, 6, 1, 2, 8, 1, 1, 2, 7, 7, 8, 7, 4, 9, 3, 6, 3, 0,\n",
       "        5, 5, 0, 6, 8, 0, 9, 7, 7, 1, 7, 5, 8, 8, 9, 1, 3, 0, 2, 5, 2, 6, 2, 4,\n",
       "        7, 1, 6, 3, 1, 3, 2, 7, 4, 3, 7, 0, 3, 8, 4, 6])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26c69ecf010>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[63].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hyperparameters for our network\n",
    "# input_size   = 784\n",
    "# hidden_sizes = [256, 128, 64]\n",
    "# output_size   = 10\n",
    "\n",
    "# # Build a feed-forward network\n",
    "# model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "#                       nn.Dropout(0.2),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "#                       nn.Dropout(0.2),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "#                       nn.Dropout(0.2),\n",
    "#                       nn.ReLU(),\n",
    "#                       nn.Linear(hidden_sizes[2], output_size),\n",
    "#                       nn.Softmax(dim=1))                          # dim is dimensionality of softmax\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with a 0.2 drop probability \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor\n",
    "        x = x.view(x.shape[0], -1)    \n",
    "        # Set the activation functions\n",
    "        layer1 = self.dropout(F.relu(self.fc1(x)))\n",
    "        layer2 = self.dropout(F.relu(self.fc2(layer1)))\n",
    "        layer3 = self.dropout(F.relu(self.fc3(layer2)))\n",
    "        out = F.log_softmax(self.fc4(layer3), dim=1)\n",
    "    \n",
    "        return out\n",
    "    \n",
    "model = Network()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize =(6, 9), ncols =2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    #ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])                          # ps is probablity\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss 0.009..  Test Loss 0.008..  Test Accuracy 0.830\n",
      "Epoch: 2/10..  Training Loss 0.008..  Test Loss 0.007..  Test Accuracy 0.828\n",
      "Epoch: 3/10..  Training Loss 0.007..  Test Loss 0.007..  Test Accuracy 0.851\n",
      "Epoch: 4/10..  Training Loss 0.007..  Test Loss 0.007..  Test Accuracy 0.840\n",
      "Epoch: 5/10..  Training Loss 0.007..  Test Loss 0.006..  Test Accuracy 0.856\n",
      "Epoch: 6/10..  Training Loss 0.006..  Test Loss 0.006..  Test Accuracy 0.856\n",
      "Epoch: 7/10..  Training Loss 0.006..  Test Loss 0.006..  Test Accuracy 0.858\n",
      "Epoch: 8/10..  Training Loss 0.006..  Test Loss 0.006..  Test Accuracy 0.857\n",
      "Epoch: 9/10..  Training Loss 0.006..  Test Loss 0.006..  Test Accuracy 0.861\n",
      "Epoch: 10/10..  Training Loss 0.006..  Test Loss 0.006..  Test Accuracy 0.868\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0 \n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "    else:\n",
    "        test_running_loss = 0\n",
    "        acc = 0\n",
    "\n",
    "        # Turn off gradients for validation to save memory and speed up computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for images, labels in testloader:\n",
    "                testoutput = model(images)\n",
    "                testloss = criterion(testoutput, labels)\n",
    "                test_running_loss += testloss.item()\n",
    "\n",
    "                ps = torch.exp(testoutput)\n",
    "                top_p, top_class = ps.topk(1, dim=1)                        # top_p = probability, top_class = index\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                acc += equals.sum().item()\n",
    "                \n",
    "        model.train()\n",
    "        \n",
    "        # Get mean loss to enable comparison between train and test sets\n",
    "        train_loss = train_running_loss/ len(trainloader.dataset)\n",
    "        test_loss = test_running_loss / len(testloader.dataset)\n",
    "        \n",
    "        # At completion of epoch\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\n",
    "              \"Training Loss {:.3f}.. \".format(train_loss),\n",
    "              \"Test Loss {:.3f}.. \".format(test_loss),\n",
    "              \"Test Accuracy {:.3f}\".format(acc / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "\n",
    "def load_model():\n",
    "  model = torch.load('checkpoint.pth')\n",
    "  return model\n",
    "   \n",
    "with st.spinner('Model is being loaded..'):\n",
    "  model = load_model()\n",
    "\n",
    "\n",
    "st.write(\"\"\"\n",
    "         # Dress Classification\n",
    "         \"\"\"\n",
    "         )\n",
    "\n",
    "file = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])\n",
    "\n",
    "\n",
    "#import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "\n",
    "def import_and_predict(image_data, model):\n",
    "    \n",
    "        size = (28, 28)    \n",
    "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
    "        image = np.asarray(image)\n",
    "        #img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
    "        \n",
    "        img_reshape = img[np.newaxis,...]\n",
    "    \n",
    "        prediction = model.predict(img_reshape)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "if file is None:\n",
    "    st.text(\"Please upload an image file\")\n",
    "else:\n",
    "    image = Image.open(file)\n",
    "    st.image(image, use_column_width=True)\n",
    "    predictions = import_and_predict(image, model)\n",
    "    score = torch.nn.Softmax(predictions[0])\n",
    "    class_names = ['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot']\n",
    "    st.write(predictions)\n",
    "    st.write(score)\n",
    "\n",
    "    print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a404c1b23560d548308d831c1aa8041fb180aef1b35cf4a28ead3655e6085d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
