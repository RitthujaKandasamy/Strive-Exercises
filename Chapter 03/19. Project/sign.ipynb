{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating csv file to gather data of images \n",
    "\n",
    "def generate_csv(root, img_ext = ['jpg', 'png', 'jpeg']):\n",
    "\n",
    "    # create a dataframe to store the data we get from the file\n",
    "    df = pd.DataFrame(columns = ['path', 'labels'])\n",
    "\n",
    "    # os.listdir gives the folder name of the files\n",
    "    for index, label in enumerate(os.listdir(root)):\n",
    "\n",
    "            links = glob(f\"{root}/{label}/*{img_ext}\")           # glob used to get all information\n",
    "            #print(len(links))\n",
    "\n",
    "            # np.ones gives 1 to total number of links and multiply with index which starts from 0\n",
    "            # np.ones(4)*3 = array([3, 3, 3, 3])\n",
    "            # so by this we get both path for images and the labels in numbers till(0 - 120)\n",
    "            temp_df = pd.DataFrame({'path': links, 'labels': np.ones(len(links))*index})\n",
    "\n",
    "            df = pd.concat([df, temp_df], axis = 0)      # merge all in one\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_csv('C:\\\\Users\\\\ritth\\\\code\\\\Data\\\\archive\\\\asl_alphabet_train\\\\asl_alphabet_train')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = train_test_split(data, test_size = 0.2, random_state = 0, stratify = data[\"labels\"])\n",
    "train_ds, test_ds = train_ds.reset_index(drop=True), test_ds.reset_index(drop=True)\n",
    "train_ds.shape, test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"path\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder_train = \"C:\\\\Users\\\\ritth\\\\code\\\\Data\\\\archive\\\\train_data\"\n",
    "dest_folder_test = \"C:\\\\Users\\\\ritth\\\\code\\\\Data\\\\archive\\\\test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(dest_folder, data):\n",
    "\n",
    "    for pth in data.values[:, 0]:            # take the path to convert into images\n",
    "\n",
    "        # 'C:\\\\Users\\\\ritth\\\\code\\\\Data\\\\datasciencebowl\\\\train\\\\train/siphonophore_physonect\\\\14249.jpg'\n",
    "        # pth.split('/')[-1] = 'siphonophore_physonect\\\\14249.jpg'\n",
    "        # ['siphonophore_physonect', '14249.jpg']\n",
    "        folder_img = pth.split(\"/\")[-1].split(\"\\\\\")     \n",
    "        folder, img = folder_img[0], folder_img[1]\n",
    "\n",
    "\n",
    "        # folder join with the path Eg:[C:\\Users\\ritth\\code\\Data\\datasciencebowl\\train_new\\trichodesmium_tuft]\n",
    "        label_folder = os.path.join(dest_folder, folder)\n",
    "\n",
    "        if not os.path.isdir(label_folder):                # if the folder does not exist \n",
    "            os.mkdir(label_folder)                         # creating the folder \n",
    "        shutil.copy(pth , label_folder)                    # copy the content of source(images) to destination(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(dest_folder_train, train_ds)\n",
    "copy_files(dest_folder_test, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),           # resize will resize all the images into same scale(same pixels) given images size are small and big, so we take approximitily 50\n",
    "                                    transforms.RandomRotation(20),\n",
    "                                    transforms.RandomResizedCrop(200),      # crop adjust the images to other images in features and we taken it as 28 smaller than resize\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        mean=[0.485, 0.456, 0.406],        # normalize have mean and standard deviation for color pic (red, green, blue)\n",
    "                                        std=[0.229, 0.224, 0.225]) \n",
    "                                    ])\n",
    "    \n",
    "    \n",
    "test_transform = transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.CenterCrop(200),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "trainset = datasets.ImageFolder(dest_folder_train, transform = train_transform)\n",
    "trainloader = DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "testset = datasets.ImageFolder(dest_folder_test,transform = test_transform)\n",
    "testloader = DataLoader(testset, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(trainloader).next()\n",
    "print(f'image size: {images[0].shape}')\n",
    "trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_normalize =  transforms.Normalize(\n",
    "    mean=-1*np.divide([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "    std=1/np.array([0.229, 0.224, 0.225])\n",
    ")\n",
    "\n",
    "def class_plot(data , classes ,inv_normalize = None,n_figures = 12):\n",
    "    n_row = int(n_figures/4)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
    "    for ax in axes.flatten():\n",
    "        idx = np.random.randint(len(data))\n",
    "        image,label = data[idx]\n",
    "        label = int(label)\n",
    "        l = classes[label]\n",
    "        if(inv_normalize!=None):\n",
    "            image = inv_normalize(image)\n",
    "        image = image.numpy().transpose(1,2,0)\n",
    "        im = ax.imshow(image)\n",
    "        ax.set_title(l)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "class_plot(trainset,trainset.classes,inv_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "\n",
    "inputs = model.fc.in_features\n",
    "outputs = len(trainset.classes)\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "clf = nn.Sequential( \n",
    "              nn.Linear(inputs, outputs)\n",
    "                  )\n",
    "\n",
    "model.fc = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_update, lr= learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "benchmark_accuracy = 0.80\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    running_accuracy = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    # training\n",
    "    for x_train_batch, y_train_batch in trainloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model.forward(x_train_batch)\n",
    "        train_preds = torch.argmax(logits.detach(), dim=1)\n",
    "\n",
    "        # loss\n",
    "        train_loss = criterion(logits, y_train_batch)\n",
    "        running_loss += train_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n",
    "        running_accuracy += train_acc.item()\n",
    "\n",
    "        # backward pass\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # mean loss (all batches losses divided by the total number of batches)\n",
    "    train_losses.append(running_loss / len(trainloader))\n",
    "\n",
    "     # mean accuracies\n",
    "    train_accuracies.append(running_accuracy / len(trainloader))\n",
    "    \n",
    "    # print\n",
    "    print(f'Train loss: {train_losses[-1] :.4f}')\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_accuracy = 0\n",
    "        running_loss = 0\n",
    "\n",
    "        for x_test_batch, y_test_batch in testloader:\n",
    "            \n",
    "            # logits\n",
    "            test_logits = model(x_test_batch)\n",
    "\n",
    "            # predictions\n",
    "            test_preds = torch.argmax(test_logits, dim=1)\n",
    "            \n",
    "            # accuracy\n",
    "            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n",
    "            running_accuracy += test_acc.item()\n",
    "            \n",
    "            # loss\n",
    "            test_loss = criterion(test_logits, y_test_batch)\n",
    "            running_loss += test_loss.item()\n",
    "\n",
    "        # mean accuracy for each epoch\n",
    "        test_accuracies.append(running_accuracy / len(testloader))\n",
    "\n",
    "        # mean loss for each epoch\n",
    "        test_losses.append(running_accuracy / len(testloader))\n",
    "\n",
    "        # print\n",
    "        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n",
    "        print('='*100)\n",
    "\n",
    "        # saving best model\n",
    "        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n",
    "        if test_accuracies[-1] > benchmark_accuracy:\n",
    "\n",
    "            # save model \n",
    "            torch.save(model.state_dict(), './model.pth')\n",
    "\n",
    "            # update benckmark\n",
    "            benchmark_accuracy = test_accuracies[-1]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# Plots\n",
    "x_epochs = list(range(epochs))\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_epochs, train_losses, marker='o', label='train')\n",
    "plt.plot(x_epochs, test_losses, marker='o', label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_epochs, train_accuracies, marker='o', label='train')\n",
    "plt.plot(x_epochs, test_accuracies, marker='o', label='test')\n",
    "plt.axhline(benchmark_accuracy, c='grey', ls='--',\n",
    "            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('./learning_curve.png', dpi = 200)\n",
    "\n",
    "plt.show()\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8abb0779bf248a90442b2ba375cb2dc444ddbc86bf34dd34983763988490020e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
