{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\ntorch.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T08:37:52.682224Z","iopub.execute_input":"2022-06-02T08:37:52.683054Z","iopub.status.idle":"2022-06-02T08:37:52.692611Z","shell.execute_reply.started":"2022-06-02T08:37:52.683009Z","shell.execute_reply":"2022-06-02T08:37:52.691797Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"# Define a transform to normalize the data (Preprocessing) and cast to tensor\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n\n# Download and load the training data\ntrainset = datasets.MNIST('MNIST_data/', download=True,\n                          train=True, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n\n# Download and load the test data\ntestset = datasets.MNIST('MNIST_data/', download=True,\n                         train=False, transform=transform)\ntestloader = DataLoader(testset, batch_size=64, shuffle=False)\n\n\nprint(trainloader.dataset)\nprint(testloader.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T08:25:30.228806Z","iopub.execute_input":"2022-06-02T08:25:30.229958Z","iopub.status.idle":"2022-06-02T08:25:30.350241Z","shell.execute_reply.started":"2022-06-02T08:25:30.229905Z","shell.execute_reply":"2022-06-02T08:25:30.348188Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"imgs, labels = iter(trainloader).next()\n\n# visualize\nplt.imshow(imgs[0].squeeze(), cmap = 'Greys_r')\nplt.title(f'{labels[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T08:26:50.213960Z","iopub.execute_input":"2022-06-02T08:26:50.214375Z","iopub.status.idle":"2022-06-02T08:26:50.415464Z","shell.execute_reply.started":"2022-06-02T08:26:50.214344Z","shell.execute_reply":"2022-06-02T08:26:50.414111Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, padding='same')\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding='same')\n        self.fc1 = nn.Linear(64*7*7, 128)\n        self.fc2 = nn.Linear(128, 10)\n        \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.log_softmax(self.fc2(x), dim=1)\n        \n        return x\n\nmodel = ConvNet()\nmodel(imgs).shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T11:23:42.624644Z","iopub.execute_input":"2022-06-02T11:23:42.625049Z","iopub.status.idle":"2022-06-02T11:23:42.669821Z","shell.execute_reply.started":"2022-06-02T11:23:42.625019Z","shell.execute_reply":"2022-06-02T11:23:42.668540Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"# Training and validation","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:58:21.752287Z","iopub.execute_input":"2022-06-02T09:58:21.752661Z","iopub.status.idle":"2022-06-02T09:58:21.761126Z","shell.execute_reply.started":"2022-06-02T09:58:21.752632Z","shell.execute_reply":"2022-06-02T09:58:21.760063Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nlearning_rate = 0.001\nepochs = 15 \n\noptimizer = optim.Adam(model.parameters(), lr= learning_rate)\ncriterion = nn.NLLLoss()\n\ntrain_losses = []\ntest_losses = []\ntrain_accuracies = []\ntest_accuracies = []\nbenchmark_accuracy = 0.98\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n    running_accuracy = 0\n    running_loss = 0\n    # training\n    for x_train_batch, y_train_batch in trainloader:\n        x_train_batch = x_train_batch.to(device)\n        y_train_batch = y_train_batch.to(device)\n\n        optimizer.zero_grad()\n\n        # forward pass\n        logits = model(x_train_batch)\n        train_preds = torch.argmax(logits.detach(), dim=1)\n\n        # loss\n        train_loss = criterion(logits, y_train_batch)\n        running_loss += train_loss.item()\n\n        # train accuracy\n        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n        running_accuracy += train_acc.item()\n\n        # backward pass\n        \n        train_loss.backward()\n        \n        # update paramaters\n        \n        optimizer.step()\n\n    # mean loss (all batches losses divided by the total number of batches)\n    train_losses.append(running_loss / len(trainloader))\n    \n    # mean accuracies\n    train_accuracies.append(running_accuracy / len(trainloader))\n    \n    # print\n    print(f'Train loss: {train_losses[-1] :.4f}')\n\n    # validation\n    model.eval()\n    with torch.no_grad():\n        running_accuracy = 0\n        running_loss = 0\n\n        for x_test_batch, y_test_batch in testloader:\n            x_test_batch = x_test_batch.to(device)\n            y_test_batch = y_test_batch.to(device)\n            # logits\n            test_logits = model(\n                x_test_batch)\n\n            # predictions\n            test_preds = torch.argmax(test_logits, dim=1)\n            \n            # accuracy\n            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n            running_accuracy += test_acc\n\n            # loss\n            test_loss = criterion(test_logits, y_test_batch)\n            running_loss += test_loss\n\n        # mean accuracy for each epoch\n        test_accuracies.append(running_accuracy / len(testloader))\n\n        # mean loss for each epoch\n        test_losses.append(running_accuracy / len(testloader))\n        # print\n        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n        print('='*100)\n        # saving best model\n        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n        if test_accuracies[-1] > benchmark_accuracy:\n            # save model to cpu\n            torch.save(model.to('cpu').state_dict(), './model.pth')\n            model.to(device) # bring back to gpu\n\n            # update benckmark\n            benchmark_accuracy = test_accuracies[-1]\n\n    model.train()\n\n\n# Plots\nx_epochs = list(range(epochs))\nplt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nplt.plot(x_epochs, train_losses, marker='o', label='train')\nplt.plot(x_epochs, test_losses, marker='o', label='test')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(x_epochs, train_accuracies, marker='o', label='train')\nplt.plot(x_epochs, test_accuracies, marker='o', label='test')\nplt.axhline(benchmark_accuracy, c='grey', ls='--',\n            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('./learning_curve.png', dpi = 200)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T11:24:09.553174Z","iopub.execute_input":"2022-06-02T11:24:09.553660Z"},"trusted":true},"execution_count":null,"outputs":[]}]}