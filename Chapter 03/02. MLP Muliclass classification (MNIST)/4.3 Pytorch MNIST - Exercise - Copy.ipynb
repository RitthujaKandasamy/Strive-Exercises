{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Clasification: MNIST</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "#from torch import pytorchtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxliary plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
    "\n",
    "def view_classify(img, ps):\n",
    "\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize =(6, 9), ncols =2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset\n",
    "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data (Preprocessing)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset    = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)                  \n",
    "\n",
    "# Download and load the test data\n",
    "testset    = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "    <h2 align=\"center\" style=\"color:#01ff84\">MNIST Clasification: Exercise</h2>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
    "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
    "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 400 units in the first hidden layer, 200 units in the second layer, and 100 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = 784\n",
    "hidden_sizes = [400, 200, 100]\n",
    "output_size  = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "          ('relu2', nn.ReLU()),\n",
    "          ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
    "          ('relu3', nn.ReLU()),\n",
    "          ('output',   nn.Linear(hidden_sizes[2], output_size)),\n",
    "          #('softmax', nn.Softmax(dim=1))\n",
    "          ]))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
    "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
    "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
    "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
    "</a></p>\n",
    "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "\tIteration: 0\t Loss: 0.1152\n",
      "\tIteration: 20\t Loss: 2.2980\n",
      "\tIteration: 40\t Loss: 2.3000\n",
      "\tIteration: 60\t Loss: 2.2976\n",
      "\tIteration: 80\t Loss: 2.2998\n",
      "\tIteration: 100\t Loss: 2.2950\n",
      "\tIteration: 120\t Loss: 2.2999\n",
      "\tIteration: 140\t Loss: 2.2958\n",
      "\tIteration: 160\t Loss: 2.2942\n",
      "\tIteration: 180\t Loss: 2.2936\n",
      "\tIteration: 200\t Loss: 2.2955\n",
      "\tIteration: 220\t Loss: 2.2952\n",
      "\tIteration: 240\t Loss: 2.2887\n",
      "\tIteration: 260\t Loss: 2.2906\n",
      "\tIteration: 280\t Loss: 2.2892\n",
      "\tIteration: 300\t Loss: 2.2882\n",
      "\tIteration: 320\t Loss: 2.2874\n",
      "\tIteration: 340\t Loss: 2.2900\n",
      "\tIteration: 360\t Loss: 2.2881\n",
      "\tIteration: 380\t Loss: 2.2861\n",
      "\tIteration: 400\t Loss: 2.2828\n",
      "\tIteration: 420\t Loss: 2.2900\n",
      "\tIteration: 440\t Loss: 2.2878\n",
      "\tIteration: 460\t Loss: 2.2888\n",
      "\tIteration: 480\t Loss: 2.2880\n",
      "\tIteration: 500\t Loss: 2.2812\n",
      "\tIteration: 520\t Loss: 2.2795\n",
      "\tIteration: 540\t Loss: 2.2842\n",
      "\tIteration: 560\t Loss: 2.2826\n",
      "\tIteration: 580\t Loss: 2.2803\n",
      "\tIteration: 600\t Loss: 2.2828\n",
      "\tIteration: 620\t Loss: 2.2797\n",
      "\tIteration: 640\t Loss: 2.2776\n",
      "\tIteration: 660\t Loss: 2.2798\n",
      "\tIteration: 680\t Loss: 2.2789\n",
      "\tIteration: 700\t Loss: 2.2771\n",
      "\tIteration: 720\t Loss: 2.2736\n",
      "\tIteration: 740\t Loss: 2.2736\n",
      "\tIteration: 760\t Loss: 2.2759\n",
      "\tIteration: 780\t Loss: 2.2760\n",
      "\tIteration: 800\t Loss: 2.2708\n",
      "\tIteration: 820\t Loss: 2.2723\n",
      "\tIteration: 840\t Loss: 2.2712\n",
      "\tIteration: 860\t Loss: 2.2685\n",
      "\tIteration: 880\t Loss: 2.2740\n",
      "\tIteration: 900\t Loss: 2.2699\n",
      "\tIteration: 920\t Loss: 2.2721\n",
      "Epoch: 2/10\n",
      "\tIteration: 0\t Loss: 0.1131\n",
      "\tIteration: 20\t Loss: 2.2652\n",
      "\tIteration: 40\t Loss: 2.2646\n",
      "\tIteration: 60\t Loss: 2.2624\n",
      "\tIteration: 80\t Loss: 2.2625\n",
      "\tIteration: 100\t Loss: 2.2613\n",
      "\tIteration: 120\t Loss: 2.2673\n",
      "\tIteration: 140\t Loss: 2.2619\n",
      "\tIteration: 160\t Loss: 2.2559\n",
      "\tIteration: 180\t Loss: 2.2587\n",
      "\tIteration: 200\t Loss: 2.2574\n",
      "\tIteration: 220\t Loss: 2.2589\n",
      "\tIteration: 240\t Loss: 2.2536\n",
      "\tIteration: 260\t Loss: 2.2565\n",
      "\tIteration: 280\t Loss: 2.2554\n",
      "\tIteration: 300\t Loss: 2.2513\n",
      "\tIteration: 320\t Loss: 2.2510\n",
      "\tIteration: 340\t Loss: 2.2505\n",
      "\tIteration: 360\t Loss: 2.2495\n",
      "\tIteration: 380\t Loss: 2.2470\n",
      "\tIteration: 400\t Loss: 2.2477\n",
      "\tIteration: 420\t Loss: 2.2478\n",
      "\tIteration: 440\t Loss: 2.2467\n",
      "\tIteration: 460\t Loss: 2.2458\n",
      "\tIteration: 480\t Loss: 2.2446\n",
      "\tIteration: 500\t Loss: 2.2432\n",
      "\tIteration: 520\t Loss: 2.2465\n",
      "\tIteration: 540\t Loss: 2.2386\n",
      "\tIteration: 560\t Loss: 2.2346\n",
      "\tIteration: 580\t Loss: 2.2361\n",
      "\tIteration: 600\t Loss: 2.2347\n",
      "\tIteration: 620\t Loss: 2.2340\n",
      "\tIteration: 640\t Loss: 2.2353\n",
      "\tIteration: 660\t Loss: 2.2323\n",
      "\tIteration: 680\t Loss: 2.2317\n",
      "\tIteration: 700\t Loss: 2.2346\n",
      "\tIteration: 720\t Loss: 2.2251\n",
      "\tIteration: 740\t Loss: 2.2232\n",
      "\tIteration: 760\t Loss: 2.2244\n",
      "\tIteration: 780\t Loss: 2.2198\n",
      "\tIteration: 800\t Loss: 2.2219\n",
      "\tIteration: 820\t Loss: 2.2230\n",
      "\tIteration: 840\t Loss: 2.2172\n",
      "\tIteration: 860\t Loss: 2.2170\n",
      "\tIteration: 880\t Loss: 2.2137\n",
      "\tIteration: 900\t Loss: 2.2118\n",
      "\tIteration: 920\t Loss: 2.2167\n",
      "Epoch: 3/10\n",
      "\tIteration: 0\t Loss: 0.1108\n",
      "\tIteration: 20\t Loss: 2.2068\n",
      "\tIteration: 40\t Loss: 2.2085\n",
      "\tIteration: 60\t Loss: 2.2077\n",
      "\tIteration: 80\t Loss: 2.2067\n",
      "\tIteration: 100\t Loss: 2.1984\n",
      "\tIteration: 120\t Loss: 2.1960\n",
      "\tIteration: 140\t Loss: 2.1940\n",
      "\tIteration: 160\t Loss: 2.1967\n",
      "\tIteration: 180\t Loss: 2.1922\n",
      "\tIteration: 200\t Loss: 2.1950\n",
      "\tIteration: 220\t Loss: 2.1874\n",
      "\tIteration: 240\t Loss: 2.1899\n",
      "\tIteration: 260\t Loss: 2.1815\n",
      "\tIteration: 280\t Loss: 2.1792\n",
      "\tIteration: 300\t Loss: 2.1803\n",
      "\tIteration: 320\t Loss: 2.1814\n",
      "\tIteration: 340\t Loss: 2.1737\n",
      "\tIteration: 360\t Loss: 2.1797\n",
      "\tIteration: 380\t Loss: 2.1762\n",
      "\tIteration: 400\t Loss: 2.1755\n",
      "\tIteration: 420\t Loss: 2.1717\n",
      "\tIteration: 440\t Loss: 2.1638\n",
      "\tIteration: 460\t Loss: 2.1654\n",
      "\tIteration: 480\t Loss: 2.1627\n",
      "\tIteration: 500\t Loss: 2.1650\n",
      "\tIteration: 520\t Loss: 2.1539\n",
      "\tIteration: 540\t Loss: 2.1565\n",
      "\tIteration: 560\t Loss: 2.1498\n",
      "\tIteration: 580\t Loss: 2.1461\n",
      "\tIteration: 600\t Loss: 2.1450\n",
      "\tIteration: 620\t Loss: 2.1390\n",
      "\tIteration: 640\t Loss: 2.1382\n",
      "\tIteration: 660\t Loss: 2.1375\n",
      "\tIteration: 680\t Loss: 2.1322\n",
      "\tIteration: 700\t Loss: 2.1278\n",
      "\tIteration: 720\t Loss: 2.1251\n",
      "\tIteration: 740\t Loss: 2.1252\n",
      "\tIteration: 760\t Loss: 2.1172\n",
      "\tIteration: 780\t Loss: 2.1225\n",
      "\tIteration: 800\t Loss: 2.1112\n",
      "\tIteration: 820\t Loss: 2.1135\n",
      "\tIteration: 840\t Loss: 2.1083\n",
      "\tIteration: 860\t Loss: 2.1032\n",
      "\tIteration: 880\t Loss: 2.0980\n",
      "\tIteration: 900\t Loss: 2.1030\n",
      "\tIteration: 920\t Loss: 2.1033\n",
      "Epoch: 4/10\n",
      "\tIteration: 0\t Loss: 0.1031\n",
      "\tIteration: 20\t Loss: 2.0803\n",
      "\tIteration: 40\t Loss: 2.0884\n",
      "\tIteration: 60\t Loss: 2.0790\n",
      "\tIteration: 80\t Loss: 2.0651\n",
      "\tIteration: 100\t Loss: 2.0659\n",
      "\tIteration: 120\t Loss: 2.0568\n",
      "\tIteration: 140\t Loss: 2.0686\n",
      "\tIteration: 160\t Loss: 2.0599\n",
      "\tIteration: 180\t Loss: 2.0518\n",
      "\tIteration: 200\t Loss: 2.0383\n",
      "\tIteration: 220\t Loss: 2.0300\n",
      "\tIteration: 240\t Loss: 2.0331\n",
      "\tIteration: 260\t Loss: 2.0406\n",
      "\tIteration: 280\t Loss: 2.0329\n",
      "\tIteration: 300\t Loss: 2.0287\n",
      "\tIteration: 320\t Loss: 2.0197\n",
      "\tIteration: 340\t Loss: 2.0158\n",
      "\tIteration: 360\t Loss: 2.0142\n",
      "\tIteration: 380\t Loss: 2.0075\n",
      "\tIteration: 400\t Loss: 2.0023\n",
      "\tIteration: 420\t Loss: 2.0026\n",
      "\tIteration: 440\t Loss: 2.0001\n",
      "\tIteration: 460\t Loss: 1.9920\n",
      "\tIteration: 480\t Loss: 1.9768\n",
      "\tIteration: 500\t Loss: 1.9766\n",
      "\tIteration: 520\t Loss: 1.9667\n",
      "\tIteration: 540\t Loss: 1.9559\n",
      "\tIteration: 560\t Loss: 1.9634\n",
      "\tIteration: 580\t Loss: 1.9510\n",
      "\tIteration: 600\t Loss: 1.9517\n",
      "\tIteration: 620\t Loss: 1.9227\n",
      "\tIteration: 640\t Loss: 1.9154\n",
      "\tIteration: 660\t Loss: 1.9262\n",
      "\tIteration: 680\t Loss: 1.9109\n",
      "\tIteration: 700\t Loss: 1.8946\n",
      "\tIteration: 720\t Loss: 1.9095\n",
      "\tIteration: 740\t Loss: 1.8873\n",
      "\tIteration: 760\t Loss: 1.9002\n",
      "\tIteration: 780\t Loss: 1.8791\n",
      "\tIteration: 800\t Loss: 1.8935\n",
      "\tIteration: 820\t Loss: 1.8624\n",
      "\tIteration: 840\t Loss: 1.8699\n",
      "\tIteration: 860\t Loss: 1.8769\n",
      "\tIteration: 880\t Loss: 1.8502\n",
      "\tIteration: 900\t Loss: 1.8245\n",
      "\tIteration: 920\t Loss: 1.8323\n",
      "Epoch: 5/10\n",
      "\tIteration: 0\t Loss: 0.0918\n",
      "\tIteration: 20\t Loss: 1.7976\n",
      "\tIteration: 40\t Loss: 1.7981\n",
      "\tIteration: 60\t Loss: 1.8199\n",
      "\tIteration: 80\t Loss: 1.7805\n",
      "\tIteration: 100\t Loss: 1.7820\n",
      "\tIteration: 120\t Loss: 1.7924\n",
      "\tIteration: 140\t Loss: 1.7559\n",
      "\tIteration: 160\t Loss: 1.7637\n",
      "\tIteration: 180\t Loss: 1.7425\n",
      "\tIteration: 200\t Loss: 1.7314\n",
      "\tIteration: 220\t Loss: 1.7556\n",
      "\tIteration: 240\t Loss: 1.7167\n",
      "\tIteration: 260\t Loss: 1.7125\n",
      "\tIteration: 280\t Loss: 1.6843\n",
      "\tIteration: 300\t Loss: 1.6898\n",
      "\tIteration: 320\t Loss: 1.6773\n",
      "\tIteration: 340\t Loss: 1.6667\n",
      "\tIteration: 360\t Loss: 1.6626\n",
      "\tIteration: 380\t Loss: 1.6482\n",
      "\tIteration: 400\t Loss: 1.6264\n",
      "\tIteration: 420\t Loss: 1.6466\n",
      "\tIteration: 440\t Loss: 1.6380\n",
      "\tIteration: 460\t Loss: 1.5941\n",
      "\tIteration: 480\t Loss: 1.6165\n",
      "\tIteration: 500\t Loss: 1.5976\n",
      "\tIteration: 520\t Loss: 1.5826\n",
      "\tIteration: 540\t Loss: 1.5784\n",
      "\tIteration: 560\t Loss: 1.5310\n",
      "\tIteration: 580\t Loss: 1.5428\n",
      "\tIteration: 600\t Loss: 1.5299\n",
      "\tIteration: 620\t Loss: 1.5245\n",
      "\tIteration: 640\t Loss: 1.5412\n",
      "\tIteration: 660\t Loss: 1.5099\n",
      "\tIteration: 680\t Loss: 1.4980\n",
      "\tIteration: 700\t Loss: 1.5201\n",
      "\tIteration: 720\t Loss: 1.4929\n",
      "\tIteration: 740\t Loss: 1.4518\n",
      "\tIteration: 760\t Loss: 1.4473\n",
      "\tIteration: 780\t Loss: 1.4683\n",
      "\tIteration: 800\t Loss: 1.4467\n",
      "\tIteration: 820\t Loss: 1.4345\n",
      "\tIteration: 840\t Loss: 1.4314\n",
      "\tIteration: 860\t Loss: 1.4297\n",
      "\tIteration: 880\t Loss: 1.4010\n",
      "\tIteration: 900\t Loss: 1.3681\n",
      "\tIteration: 920\t Loss: 1.4123\n",
      "Epoch: 6/10\n",
      "\tIteration: 0\t Loss: 0.0656\n",
      "\tIteration: 20\t Loss: 1.3600\n",
      "\tIteration: 40\t Loss: 1.3420\n",
      "\tIteration: 60\t Loss: 1.3340\n",
      "\tIteration: 80\t Loss: 1.3351\n",
      "\tIteration: 100\t Loss: 1.3271\n",
      "\tIteration: 120\t Loss: 1.3111\n",
      "\tIteration: 140\t Loss: 1.3205\n",
      "\tIteration: 160\t Loss: 1.2922\n",
      "\tIteration: 180\t Loss: 1.2780\n",
      "\tIteration: 200\t Loss: 1.2668\n",
      "\tIteration: 220\t Loss: 1.2815\n",
      "\tIteration: 240\t Loss: 1.2246\n",
      "\tIteration: 260\t Loss: 1.2832\n",
      "\tIteration: 280\t Loss: 1.2670\n",
      "\tIteration: 300\t Loss: 1.2461\n",
      "\tIteration: 320\t Loss: 1.2295\n",
      "\tIteration: 340\t Loss: 1.2130\n",
      "\tIteration: 360\t Loss: 1.2144\n",
      "\tIteration: 380\t Loss: 1.2255\n",
      "\tIteration: 400\t Loss: 1.2383\n",
      "\tIteration: 420\t Loss: 1.1645\n",
      "\tIteration: 440\t Loss: 1.1960\n",
      "\tIteration: 460\t Loss: 1.1853\n",
      "\tIteration: 480\t Loss: 1.1749\n",
      "\tIteration: 500\t Loss: 1.1607\n",
      "\tIteration: 520\t Loss: 1.1360\n",
      "\tIteration: 540\t Loss: 1.1171\n",
      "\tIteration: 560\t Loss: 1.1242\n",
      "\tIteration: 580\t Loss: 1.1094\n",
      "\tIteration: 600\t Loss: 1.1027\n",
      "\tIteration: 620\t Loss: 1.1042\n",
      "\tIteration: 640\t Loss: 1.1119\n",
      "\tIteration: 660\t Loss: 1.0993\n",
      "\tIteration: 680\t Loss: 1.0567\n",
      "\tIteration: 700\t Loss: 1.1150\n",
      "\tIteration: 720\t Loss: 1.0808\n",
      "\tIteration: 740\t Loss: 1.0765\n",
      "\tIteration: 760\t Loss: 1.0629\n",
      "\tIteration: 780\t Loss: 1.0348\n",
      "\tIteration: 800\t Loss: 1.0226\n",
      "\tIteration: 820\t Loss: 1.0199\n",
      "\tIteration: 840\t Loss: 0.9988\n",
      "\tIteration: 860\t Loss: 1.0361\n",
      "\tIteration: 880\t Loss: 1.0073\n",
      "\tIteration: 900\t Loss: 0.9792\n",
      "\tIteration: 920\t Loss: 1.0097\n",
      "Epoch: 7/10\n",
      "\tIteration: 0\t Loss: 0.0439\n",
      "\tIteration: 20\t Loss: 0.9988\n",
      "\tIteration: 40\t Loss: 0.9893\n",
      "\tIteration: 60\t Loss: 0.9662\n",
      "\tIteration: 80\t Loss: 0.9445\n",
      "\tIteration: 100\t Loss: 0.9923\n",
      "\tIteration: 120\t Loss: 0.9375\n",
      "\tIteration: 140\t Loss: 0.9561\n",
      "\tIteration: 160\t Loss: 0.9870\n",
      "\tIteration: 180\t Loss: 0.9493\n",
      "\tIteration: 200\t Loss: 0.9151\n",
      "\tIteration: 220\t Loss: 0.9301\n",
      "\tIteration: 240\t Loss: 0.9178\n",
      "\tIteration: 260\t Loss: 0.9013\n",
      "\tIteration: 280\t Loss: 0.9134\n",
      "\tIteration: 300\t Loss: 0.9197\n",
      "\tIteration: 320\t Loss: 0.9049\n",
      "\tIteration: 340\t Loss: 0.9075\n",
      "\tIteration: 360\t Loss: 0.9050\n",
      "\tIteration: 380\t Loss: 0.8702\n",
      "\tIteration: 400\t Loss: 0.8796\n",
      "\tIteration: 420\t Loss: 0.8846\n",
      "\tIteration: 440\t Loss: 0.8712\n",
      "\tIteration: 460\t Loss: 0.8513\n",
      "\tIteration: 480\t Loss: 0.8833\n",
      "\tIteration: 500\t Loss: 0.8676\n",
      "\tIteration: 520\t Loss: 0.8712\n",
      "\tIteration: 540\t Loss: 0.8603\n",
      "\tIteration: 560\t Loss: 0.7954\n",
      "\tIteration: 580\t Loss: 0.8114\n",
      "\tIteration: 600\t Loss: 0.8086\n",
      "\tIteration: 620\t Loss: 0.8667\n",
      "\tIteration: 640\t Loss: 0.8296\n",
      "\tIteration: 660\t Loss: 0.8353\n",
      "\tIteration: 680\t Loss: 0.8229\n",
      "\tIteration: 700\t Loss: 0.8599\n",
      "\tIteration: 720\t Loss: 0.8056\n",
      "\tIteration: 740\t Loss: 0.8163\n",
      "\tIteration: 760\t Loss: 0.8290\n",
      "\tIteration: 780\t Loss: 0.7946\n",
      "\tIteration: 800\t Loss: 0.8216\n",
      "\tIteration: 820\t Loss: 0.7951\n",
      "\tIteration: 840\t Loss: 0.8085\n",
      "\tIteration: 860\t Loss: 0.8104\n",
      "\tIteration: 880\t Loss: 0.8162\n",
      "\tIteration: 900\t Loss: 0.8133\n",
      "\tIteration: 920\t Loss: 0.8221\n",
      "Epoch: 8/10\n",
      "\tIteration: 0\t Loss: 0.0504\n",
      "\tIteration: 20\t Loss: 0.7830\n",
      "\tIteration: 40\t Loss: 0.7626\n",
      "\tIteration: 60\t Loss: 0.7770\n",
      "\tIteration: 80\t Loss: 0.7771\n",
      "\tIteration: 100\t Loss: 0.7997\n",
      "\tIteration: 120\t Loss: 0.7712\n",
      "\tIteration: 140\t Loss: 0.7734\n",
      "\tIteration: 160\t Loss: 0.7621\n",
      "\tIteration: 180\t Loss: 0.7358\n",
      "\tIteration: 200\t Loss: 0.7360\n",
      "\tIteration: 220\t Loss: 0.7418\n",
      "\tIteration: 240\t Loss: 0.7278\n",
      "\tIteration: 260\t Loss: 0.7530\n",
      "\tIteration: 280\t Loss: 0.7267\n",
      "\tIteration: 300\t Loss: 0.7116\n",
      "\tIteration: 320\t Loss: 0.7270\n",
      "\tIteration: 340\t Loss: 0.6955\n",
      "\tIteration: 360\t Loss: 0.7318\n",
      "\tIteration: 380\t Loss: 0.7364\n",
      "\tIteration: 400\t Loss: 0.7421\n",
      "\tIteration: 420\t Loss: 0.7190\n",
      "\tIteration: 440\t Loss: 0.7068\n",
      "\tIteration: 460\t Loss: 0.7622\n",
      "\tIteration: 480\t Loss: 0.7390\n",
      "\tIteration: 500\t Loss: 0.7090\n",
      "\tIteration: 520\t Loss: 0.7231\n",
      "\tIteration: 540\t Loss: 0.6929\n",
      "\tIteration: 560\t Loss: 0.6726\n",
      "\tIteration: 580\t Loss: 0.6805\n",
      "\tIteration: 600\t Loss: 0.6924\n",
      "\tIteration: 620\t Loss: 0.6912\n",
      "\tIteration: 640\t Loss: 0.6628\n",
      "\tIteration: 660\t Loss: 0.6538\n",
      "\tIteration: 680\t Loss: 0.6670\n",
      "\tIteration: 700\t Loss: 0.7222\n",
      "\tIteration: 720\t Loss: 0.6830\n",
      "\tIteration: 740\t Loss: 0.6718\n",
      "\tIteration: 760\t Loss: 0.7041\n",
      "\tIteration: 780\t Loss: 0.6587\n",
      "\tIteration: 800\t Loss: 0.6781\n",
      "\tIteration: 820\t Loss: 0.6627\n",
      "\tIteration: 840\t Loss: 0.6549\n",
      "\tIteration: 860\t Loss: 0.6617\n",
      "\tIteration: 880\t Loss: 0.6687\n",
      "\tIteration: 900\t Loss: 0.6490\n",
      "\tIteration: 920\t Loss: 0.6548\n",
      "Epoch: 9/10\n",
      "\tIteration: 0\t Loss: 0.0302\n",
      "\tIteration: 20\t Loss: 0.6745\n",
      "\tIteration: 40\t Loss: 0.6489\n",
      "\tIteration: 60\t Loss: 0.6180\n",
      "\tIteration: 80\t Loss: 0.6541\n",
      "\tIteration: 100\t Loss: 0.6544\n",
      "\tIteration: 120\t Loss: 0.6025\n",
      "\tIteration: 140\t Loss: 0.6284\n",
      "\tIteration: 160\t Loss: 0.5997\n",
      "\tIteration: 180\t Loss: 0.6661\n",
      "\tIteration: 200\t Loss: 0.6300\n",
      "\tIteration: 220\t Loss: 0.6094\n",
      "\tIteration: 240\t Loss: 0.6168\n",
      "\tIteration: 260\t Loss: 0.6508\n",
      "\tIteration: 280\t Loss: 0.6688\n",
      "\tIteration: 300\t Loss: 0.6118\n",
      "\tIteration: 320\t Loss: 0.5901\n",
      "\tIteration: 340\t Loss: 0.6321\n",
      "\tIteration: 360\t Loss: 0.6288\n",
      "\tIteration: 380\t Loss: 0.6154\n",
      "\tIteration: 400\t Loss: 0.6280\n",
      "\tIteration: 420\t Loss: 0.5970\n",
      "\tIteration: 440\t Loss: 0.6280\n",
      "\tIteration: 460\t Loss: 0.6272\n",
      "\tIteration: 480\t Loss: 0.5699\n",
      "\tIteration: 500\t Loss: 0.6267\n",
      "\tIteration: 520\t Loss: 0.6171\n",
      "\tIteration: 540\t Loss: 0.5915\n",
      "\tIteration: 560\t Loss: 0.5936\n",
      "\tIteration: 580\t Loss: 0.5994\n",
      "\tIteration: 600\t Loss: 0.6216\n",
      "\tIteration: 620\t Loss: 0.6078\n",
      "\tIteration: 640\t Loss: 0.6065\n",
      "\tIteration: 660\t Loss: 0.6028\n",
      "\tIteration: 680\t Loss: 0.6116\n",
      "\tIteration: 700\t Loss: 0.6100\n",
      "\tIteration: 720\t Loss: 0.5977\n",
      "\tIteration: 740\t Loss: 0.6111\n",
      "\tIteration: 760\t Loss: 0.5891\n",
      "\tIteration: 780\t Loss: 0.5752\n",
      "\tIteration: 800\t Loss: 0.5888\n",
      "\tIteration: 820\t Loss: 0.5862\n",
      "\tIteration: 840\t Loss: 0.5756\n",
      "\tIteration: 860\t Loss: 0.6102\n",
      "\tIteration: 880\t Loss: 0.5947\n",
      "\tIteration: 900\t Loss: 0.5945\n",
      "\tIteration: 920\t Loss: 0.5850\n",
      "Epoch: 10/10\n",
      "\tIteration: 0\t Loss: 0.0351\n",
      "\tIteration: 20\t Loss: 0.5413\n",
      "\tIteration: 40\t Loss: 0.5776\n",
      "\tIteration: 60\t Loss: 0.5664\n",
      "\tIteration: 80\t Loss: 0.5644\n",
      "\tIteration: 100\t Loss: 0.5801\n",
      "\tIteration: 120\t Loss: 0.5635\n",
      "\tIteration: 140\t Loss: 0.5770\n",
      "\tIteration: 160\t Loss: 0.5823\n",
      "\tIteration: 180\t Loss: 0.5720\n",
      "\tIteration: 200\t Loss: 0.5675\n",
      "\tIteration: 220\t Loss: 0.5748\n",
      "\tIteration: 240\t Loss: 0.5635\n",
      "\tIteration: 260\t Loss: 0.5194\n",
      "\tIteration: 280\t Loss: 0.5762\n",
      "\tIteration: 300\t Loss: 0.5308\n",
      "\tIteration: 320\t Loss: 0.5354\n",
      "\tIteration: 340\t Loss: 0.5634\n",
      "\tIteration: 360\t Loss: 0.5385\n",
      "\tIteration: 380\t Loss: 0.5329\n",
      "\tIteration: 400\t Loss: 0.5697\n",
      "\tIteration: 420\t Loss: 0.5227\n",
      "\tIteration: 440\t Loss: 0.5542\n",
      "\tIteration: 460\t Loss: 0.5414\n",
      "\tIteration: 480\t Loss: 0.5263\n",
      "\tIteration: 500\t Loss: 0.5448\n",
      "\tIteration: 520\t Loss: 0.5411\n",
      "\tIteration: 540\t Loss: 0.5494\n",
      "\tIteration: 560\t Loss: 0.5739\n",
      "\tIteration: 580\t Loss: 0.5544\n",
      "\tIteration: 600\t Loss: 0.5436\n",
      "\tIteration: 620\t Loss: 0.5283\n",
      "\tIteration: 640\t Loss: 0.4954\n",
      "\tIteration: 660\t Loss: 0.5574\n",
      "\tIteration: 680\t Loss: 0.5771\n",
      "\tIteration: 700\t Loss: 0.5449\n",
      "\tIteration: 720\t Loss: 0.5512\n",
      "\tIteration: 740\t Loss: 0.5512\n",
      "\tIteration: 760\t Loss: 0.5452\n",
      "\tIteration: 780\t Loss: 0.5332\n",
      "\tIteration: 800\t Loss: 0.5253\n",
      "\tIteration: 820\t Loss: 0.5412\n",
      "\tIteration: 840\t Loss: 0.5405\n",
      "\tIteration: 860\t Loss: 0.4926\n",
      "\tIteration: 880\t Loss: 0.5026\n",
      "\tIteration: 900\t Loss: 0.5237\n",
      "\tIteration: 920\t Loss: 0.5214\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "print_every = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(iter(trainloader)):       \n",
    "\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)   \n",
    "        loss = criterion(output, labels) \n",
    "        loss.backward()                  \n",
    "        optimizer.step()                 \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 195,
       "width": 349
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
    "images, labels = next(iter(testloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "logits = model.forward(images[0,:])\n",
    "ps = F.softmax(logits, dim=1)\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
    "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
    "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
    "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "\tIteration: 0\t Loss: 0.0223\n",
      "\tIteration: 20\t Loss: 0.4589\n",
      "\tIteration: 40\t Loss: 0.4586\n",
      "\tIteration: 60\t Loss: 0.4568\n",
      "\tIteration: 80\t Loss: 0.4357\n",
      "\tIteration: 100\t Loss: 0.4168\n",
      "\tIteration: 120\t Loss: 0.4064\n",
      "\tIteration: 140\t Loss: 0.4322\n",
      "\tIteration: 160\t Loss: 0.4228\n",
      "\tIteration: 180\t Loss: 0.4691\n",
      "\tIteration: 200\t Loss: 0.4670\n",
      "\tIteration: 220\t Loss: 0.4319\n"
     ]
    }
   ],
   "source": [
    "def train(num_epochs, optimizer, criterion, trainloader):\n",
    "\n",
    "    # Early stopping\n",
    "    the_last_loss = 100\n",
    "    patience = 2\n",
    "    trigger_times = 0\n",
    "    num_epochs = 10\n",
    "    print_every = 20\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for i, (images, labels) in enumerate(iter(trainloader)):       \n",
    "\n",
    "            # Flatten MNIST images into a 784 long vector\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)   \n",
    "            loss = criterion(output, labels) \n",
    "            loss.backward()                  \n",
    "            optimizer.step()                 \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
    "                running_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "        # Early stopping\n",
    "        the_current_loss = test(trainloader, criterion)\n",
    "        print('The current loss:', the_current_loss)\n",
    "\n",
    "        if the_current_loss > the_last_loss:\n",
    "            trigger_times += 1\n",
    "            print('trigger times:', trigger_times)\n",
    "\n",
    "            if trigger_times >= patience:\n",
    "                print('Early stopping!\\nStart to test process.')\n",
    "                #return model\n",
    "\n",
    "        else:\n",
    "            print('trigger times: 0')\n",
    "            trigger_times = 0\n",
    "\n",
    "        the_last_loss = the_current_loss\n",
    "\n",
    "    #return model\n",
    "\n",
    "train(num_epochs, optimizer, criterion, trainloader)\n",
    "\n",
    "\n",
    "\n",
    "# test model\n",
    "def test(testloader):\n",
    "\n",
    "    # Settings\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images.resize_(images.size()[0], 784)\n",
    "\n",
    "            output = model.forward(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accurcy:', correct / total)\n",
    "\n",
    "test(testloader)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a404c1b23560d548308d831c1aa8041fb180aef1b35cf4a28ead3655e6085d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
