{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches, Batch Normalization and Dropout\n",
    "\n",
    "In this workbook you can experiment what you learnt about how to make batches out of your data, how to perform batch normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from data/batches_norm_drop.csv, then take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350140</td>\n",
       "      <td>4.248592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950728</td>\n",
       "      <td>3.528855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.371517</td>\n",
       "      <td>3.149416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268221</td>\n",
       "      <td>4.337209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.881996</td>\n",
       "      <td>1.515387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>-3.425455</td>\n",
       "      <td>3.349783</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>-1.513002</td>\n",
       "      <td>2.789840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-1.070356</td>\n",
       "      <td>3.484981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>-2.970848</td>\n",
       "      <td>3.443924</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-2.575695</td>\n",
       "      <td>2.140739</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1  2\n",
       "0    0.350140  4.248592  0\n",
       "1    0.950728  3.528855  0\n",
       "2    1.371517  3.149416  0\n",
       "3    0.268221  4.337209  0\n",
       "4    1.881996  1.515387  0\n",
       "..        ...       ... ..\n",
       "745 -3.425455  3.349783  2\n",
       "746 -1.513002  2.789840  2\n",
       "747 -1.070356  3.484981  2\n",
       "748 -2.970848  3.443924  2\n",
       "749 -2.575695  2.140739  2\n",
       "\n",
       "[750 rows x 3 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/batches_norm_drop.csv', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop([2], axis=1))\n",
    "y = np.array(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (750, 2)\n",
      "[[ 0.35014034  4.24859167]\n",
      " [ 0.95072765  3.52885487]\n",
      " [ 1.37151689  3.1494165 ]\n",
      " ...\n",
      " [-1.07035566  3.48498144]\n",
      " [-2.97084772  3.44392411]\n",
      " [-2.57569525  2.14073863]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\",X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to code your own function to create batches. If needed rewatch the video we provided in Eduflow.\n",
    "\n",
    "**Extra challange:**    Are you able to split between train and test _**without**_ using sklearn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of rows in train: 600\n",
      "Total Number of rows in test: 150\n"
     ]
    }
   ],
   "source": [
    "n_train = math.floor(0.8 * X.shape[0])\n",
    "n_test = math.ceil((1 - 0.8) * X.shape[0])\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "y_test = y[n_train:]\n",
    "print(\"Total Number of rows in train:\",X_train.shape[0])\n",
    "print(\"Total Number of rows in test:\",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 2), (150, 2), (600,), (150,))"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(675, 2) (75, 2) (675,) (75,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.astype(np.float32))\n",
    "X_test = torch.tensor(X_test.astype(np.float32))\n",
    "\n",
    "y_train = torch.tensor(y_train.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3716,  3.3764],\n",
       "        [-1.8756,  2.1604],\n",
       "        [ 1.6756,  2.0155],\n",
       "        ...,\n",
       "        [-0.6526,  3.2613],\n",
       "        [-2.5773,  4.6756],\n",
       "        [-2.9603,  4.9623]])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 15\n",
    "\n",
    "\n",
    "n_batches = X_train.shape[0] // batch_size  \n",
    "n_batches_test = X_test.shape[0] // batch_size\n",
    "print(n_batches)\n",
    "\n",
    "\n",
    "indexes = np.random.permutation(X_train.shape[0])\n",
    "indexes_test = np.random.permutation(X_test.shape[0])\n",
    "#print(indexes)\n",
    "\n",
    "\n",
    "X_train = X_train[indexes]\n",
    "y_train = y_train[indexes]\n",
    "\n",
    "X_test = X_test[indexes_test]\n",
    "y_test = y_test[indexes_test]\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train[ :batch_size * n_batches ].reshape(n_batches, batch_size, X_train.shape[1])\n",
    "y_train = y_train[ :batch_size * n_batches ].reshape(n_batches, batch_size, 1)\n",
    "#print(X_train)\n",
    "\n",
    "X_test = X_test[ :batch_size * n_batches_test ].reshape(n_batches_test, batch_size, X_test.shape[1])\n",
    "y_test = y_test[ :batch_size * n_batches_test ].reshape(n_batches_test, batch_size, 1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 15, 2])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to create your model! Remember to include the new tricks you learnt (batch normalization and dropout)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=45, out_features=400, bias=True)\n",
      "  (1): Softmax(dim=1)\n",
      "  (2): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (3): Softmax(dim=1)\n",
      "  (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      "  (6): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size   = X_train.shape[2]\n",
    "hidden_sizes = [400, 200, 100]\n",
    "output_size   = 1\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      #nn.BatchNorm1d(400),\n",
    "                      #nn.Dropout(0.2),\n",
    "                      nn.Softmax(dim = 1),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      #nn.BatchNorm1d(200),\n",
    "                      #nn.Dropout(0.2),\n",
    "                      nn.Softmax(dim = 1),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                      #nn.BatchNorm1d(100),\n",
    "                      #nn.Dropout(0.1),\n",
    "                      nn.Softmax(dim = 1),\n",
    "                      nn.Linear(hidden_sizes[2], output_size),\n",
    "                      \n",
    "                      \n",
    "                      )                \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model and evaluate it. **Extra challenge**: try to figure out how you can tell if batch norm and dropout are effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()             \n",
    "trainloss = []\n",
    "testloss = []\n",
    "num_epochs = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (15x2 and 45x400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ritth\\code\\Strive\\Strive-Exercises\\Chapter 03\\04. DataLoader\\Batches_BatchNorm_Dropout.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000024?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m X_train_batches, y_train_batches \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_train, y_train):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000024?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()             \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000024?line=6'>7</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model(X_train_batches)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000024?line=7'>8</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(y_pred, y_train_batches)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ritth/code/Strive/Strive-Exercises/Chapter%2003/04.%20DataLoader/Batches_BatchNorm_Dropout.ipynb#ch0000024?line=8'>9</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\ritth\\software\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ritth\\software\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ritth\\software\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ritth\\software\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ritth/software/anaconda/envs/deep/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (15x2 and 45x400)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        for X_train_batches, y_train_batches in zip(X_train, y_train):\n",
    "            model.train()             \n",
    "            y_pred = model(X_train_batches)\n",
    "            loss = criterion(y_pred, y_train_batches)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            trainloss.append(running_loss / X_train.shape[0])\n",
    "            \n",
    "            \n",
    "        \n",
    "        # test\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for X_test_batches, y_test_batches in zip(X_test, y_test):\n",
    "\n",
    "                test_pred = model(X_test_batches)\n",
    "                test_loss = criterion(test_pred, y_test_batches)\n",
    "                running_loss += test_loss.item()\n",
    "                testloss.append(running_loss / X_test.shape[0])\n",
    "               \n",
    "        \n",
    "\n",
    "                print(f'Epoch: {epoch}, train loss: {loss.item():.2f}, test loss: {test_loss.item():.2f}')\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "# plt.figure(figsize = (10, 8))\n",
    "# plt.title(\"Loss for Train and Test\")\n",
    "# plt.plot(trainloss, marker = 'o', label = 'Train Loss')\n",
    "# plt.plot(testloss, marker = 'o', label = 'Test Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a404c1b23560d548308d831c1aa8041fb180aef1b35cf4a28ead3655e6085d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
